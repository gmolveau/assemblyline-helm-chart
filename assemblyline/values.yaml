# Tags for the containers used
coreVersion: '4.0.0.stable2'
sapiVersion: '4.0.0.stable1'
uiVersion: '4.0.0.stable1'

# Images for containers used
assemblylineCoreImage: cccs/assemblyline-core
assemblylineUIImage: cccs/assemblyline-ui
assemblylineSocketIOImage: cccs/assemblyline-socketio
assemblylineServiceAPIImage: cccs/assemblyline-service-server
assemblylineServiceImagePrefix: cccs/assemblyline-service-
elasticAPMImage: docker.elastic.co/apm/apm-server
elasticLogstashImage: docker.elastic.co/logstash/logstash
NFSImage: apnar/nfs-ganesha
redisImage: redis

# Storage classes for persistent data.
redisStorageClass: redis-storage
updateStorageClass: update-storage

# When true an elk stack is launched inside assemblyline to collect logs and metrics
# Otherwise, logstash is run, but no kibana or elasticsearch for logs
internalLogging: true

# Many kubernetes environments don't provide multiple read multiple write volumes.
# We want to use them, but they don't have to be high performance. If this flag
# is true, assemblyline will launch NFS servers internally to get RWX volumes.
# Otherwise, the storage class for updateStorageClass needs to support RWX
internalNFS: true

# If you have an ftp server, s3 bucket, azure blob storage account or other
# supported blob storage where you would like assemblyline to store the files
# that are submitted set `internalFilestore` to false, and set the url
# for your storage system to the `configuration.filestore.*` fields.
internalFilestore: true

# Launch an elastic APM server to collect profiling data and report it to the logging
# elasticsearch database.
# TODO The assemblyline config entry for apm address is statically set to this
#      whether it is created or not. Some way to switch it off when this is false
#      would be nice
enableAPM: false

# If internal logging is not used, this specifies where to write metrics and logs.
# Ignored when internal logging is set.
loggingHost:
kibanaHost: http://kibana/kibana
loggingUsername: "elastic"
loggingTLSVerify: "full"

# Values used to configure the ingress
ingressAnnotations: {}
# This field is not required and will be set automatically if the field
# configuration.ui.fqdn is defined. Only set this field directly when you need
# the ingress to use a different value. Otherwise, set your domain there.
ingressHost:
# If a tls secret name is given here, that certificate will be used for https
# If left null, a self signed cert will be generated.
tlsSecretName:

# Bootstrap process settings
# Whether an admin account should be created by the back end.
#   Accepted Values:
#     'on-install' only try to create an admin user when performing a helm install
#     'always' run the create command on every helm upgrade and install
#     'never' (or any other value) will not run the setup container
# The password for this admin account will be drawn from the initial-admin-password
# key of the assemblyline-system-passwords secret
createAdminAccount: 'on-install'

# A list of services to be installed, only run during a helm install.
autoInstallServices:
  - apkaye
  - beaver
  - characterize
  - configextractor
  - cuckoo
  - deobfuscripter
  - emlparser
  - espresso
  - extract
  - frankenstrings
  - floss
  - iparse
  - metadefender
  - metapeek
  - oletools
  - pdfid
  - peepdf
  - pefile
  - pixaxe
  - suricata
  - swiffer
  - tagcheck
  - torrentslicer
  - unpacker
  - vipermonkey
  - virustotal-dynamic
  - virustotal-static
  - xlmmacrodeobfuscator
  - yara

# Extra environment variables, mounts, and volumes shared by all core containers
# Any environment variables set here can be used in the value strings of any
# field under the configuration.* block. This is the proper way to pass a secret
# to the assemblyline core components. These values won't be passed to analysis
# services.
coreEnv: []
coreMounts: []
coreVolumes: []

# A logstash pipeline is set by default that will write to the internal elasticsearch
# instance or to the given 'loggingHost' value. A pipeline passed as a string here
# can be used for deeper customization
customLogstashPipeline: null

# You may want mount custom pipeline files or certificates if you are using
# a custom logstash pipeline
logstashVolumes:
logstashMounts:

# Internal configuration for assemblyline components. See the assemblyline
# administration documentation for more details.
# https://cybercentrecanada.github.io/assemblyline4_docs/
configuration:
  core:
    alerter:
      delay: 0
    dispatcher:
      max_inflight: 10000
    ingester:
      max_inflight: 6000
    metrics:
      apm_server:
        server_url: "http://apm:8200"
      elasticsearch:
        hosts: ["http://${LOGGING_USERNAME}:${LOGGING_PASSWORD}@${LOGGING_HOST}"]
      redis:
        host: redis-volatile
        port: 6379
    redis:
      nonpersistent:
        host: redis-volatile
        port: 6379
      persistent:
        host: redis-persistent
        port: 6379
    scaler:
      service_defaults:
        backlog: 10
        min_instances: 1
        growth: 60
        shrink: 20
        environment:
          - name: 'SERVICE_API_HOST'
            value: 'http://service-server:5003'
  datastore:
    hosts: ["http://elastic:${ELASTIC_PASSWORD}@datastore-master:9200"]
  filestore:
    cache: ["s3://${INTERNAL_FILESTORE_ACCESS}:${INTERNAL_FILESTORE_KEY}@filestore:9000?s3_bucket=al-cache&use_ssl=False"]
    storage: ["s3://${INTERNAL_FILESTORE_ACCESS}:${INTERNAL_FILESTORE_KEY}@filestore:9000?s3_bucket=al-storage&use_ssl=False"]
  logging:
    log_to_console: true
    log_to_file: false
    log_to_syslog: false
  ui:
    fqdn: "localhost"

# Configuration for the elasticsearch instance used for system data.
# Values an administrator is likely to want to change to scale their deployment are:
#     replicas
#     resources
#     volumeClaimTemplate
datastore:
  clusterName: "datastore"
  replicas: 3
  extraEnvs:
    - name: ELASTIC_USERNAME
      value: elastic
    - name: ELASTIC_PASSWORD
      valueFrom:
        secretKeyRef:
          name: assemblyline-system-passwords
          key: datastore-password
  labels:
    section: core
    component: datastore
  protocol: http
  esJavaOpts: '-Xms4g -Xmx4g'
  esConfig:
    elasticsearch.yml: |
      logger.level: WARN
      xpack.security.enabled: true
      xpack.security.transport.ssl.enabled: true
      xpack.security.transport.ssl.verification_mode: certificate
      xpack.security.transport.ssl.keystore.path: /usr/share/elasticsearch/config/certs/elastic-certificates.p12
      xpack.security.transport.ssl.truststore.path: /usr/share/elasticsearch/config/certs/elastic-certificates.p12
      xpack.security.http.ssl.enabled: false
      xpack.security.http.ssl.truststore.path: /usr/share/elasticsearch/config/certs/elastic-certificates.p12
      xpack.security.http.ssl.keystore.path: /usr/share/elasticsearch/config/certs/elastic-certificates.p12
  resources:
    requests:
      cpu: 1
      memory: 5Gi
    limits:
      cpu: 4
      memory: 6Gi
  volumeClaimTemplate:
    accessModes: [ "ReadWriteOnce" ]
    storageClassName: default
    resources:
      requests:
        storage: 500Gi
  priorityClassName: 'al-infra'
  extraInitContainers: |
    - name: create-certs
      image: docker.elastic.co/elasticsearch/elasticsearch:7.8.0
      command: ['bash', '-c', "if [ ! -f /data/elastic-certificates.p12 ]; then mkdir /tmp/certs/ && elasticsearch-certutil ca --out /tmp/certs/elastic-stack-ca.p12 --pass '' && elasticsearch-certutil cert --name security-master --dns security-master --ca /tmp/certs/elastic-stack-ca.p12 --pass '' --ca-pass '' --out /tmp/certs/elastic-certificates.p12 && mv -n /tmp/certs/* /data/; fi"]
      volumeMounts:
        - name: elastic-certificates
          mountPath: /data/
  extraVolumes: |
    - name: elastic-certificates
      persistentVolumeClaim:
        claimName: datastore-certificates
  extraVolumeMounts: |
    - name: elastic-certificates
      mountPath: /usr/share/elasticsearch/config/certs


filebeat:
  labels:
    section: core
    component: filebeat
  extraPorts:
    - name: beats
      containerPort: 5044
  extraEnvs:
    - name: ELASTICSEARCH_HOSTS
      valueFrom:
        configMapKeyRef:
          name: system-settings
          key: logging-host
    - name: ELASTICSEARCH_USERNAME
      valueFrom:
        configMapKeyRef:
          name: system-settings
          key: logging-username
    - name: ELASTICSEARCH_PASSWORD
      valueFrom:
        secretKeyRef:
          name: assemblyline-system-passwords
          key: logging-password
    - name: LOGGING_TLS_VERIFY
      valueFrom:
        configMapKeyRef:
          name: system-settings
          key: logging-tls-verify
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
  filebeatConfig:
    filebeat.yml: |-
      logging:
        level: warning
        json: true
      name: ${NODE_NAME}

      filebeat.inputs:
        - type: container
          format: docker
          paths:
            - '/var/lib/docker/containers/*/*.log'
          stream: "all"
          json:
            keys_under_root: true
            message_key: message
            ignore_decoding_error: true
          processors:
            - rename:
                fields:
                  - from: "error"
                    to: "error.message"
                ignore_missing: true
            - script:
                lang: javascript
                id: log_level
                source: >
                  function process(event) {
                      var value = event.Get("log.level");
                      if (value === null){
                        value = "INFO"
                      }
                      else if (value.toLowerCase() == "warn"){
                        value = "WARNING"
                      }
                      else if (value.toLowerCase() == "err"){
                        value = "ERROR"
                      }
                      event.Put("log.level", value.toUpperCase());
                  }

      processors:
        - add_cloud_metadata: ~
        - add_host_metadata: ~
        - add_docker_metadata: ~
        - add_kubernetes_metadata: ~
        - drop_event:
            when:
              or:
                - regexp:
                    container.labels.io_kubernetes_container_name: "(nginx-ingress-controller)|(tunnel-front)"
                - equals:
                    kubernetes.namespace: kube-system

      output.logstash:
        hosts: ["logstash:5044"]


metricbeatIndexPrefix: "metricbeat"

metricbeat:
  labels:
    section: core
    component: metricbeat
  deployment:
    extraVolumeMounts:
    - name: dockersock
      mountPath: /var/run/docker.sock
    extraVolumes:
    - name: dockersock
      hostPath:
        path: /var/run/docker.sock
    extraEnvs:
      - name: ELASTICSEARCH_HOSTS
        valueFrom:
          configMapKeyRef:
            name: system-settings
            key: logging-host
      - name: ELASTICSEARCH_USERNAME
        valueFrom:
          configMapKeyRef:
            name: system-settings
            key: logging-username
      - name: ELASTICSEARCH_PASSWORD
        valueFrom:
          secretKeyRef:
            name: assemblyline-system-passwords
            key: logging-password
      - name: LOGGING_TLS_VERIFY
        valueFrom:
          configMapKeyRef:
            name: system-settings
            key: logging-tls-verify
      - name: METRICBEAT_INDEX
        valueFrom:
          configMapKeyRef:
            name: system-settings
            key: metricbeat-index-prefix
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            fieldPath: spec.nodeName
  daemonset:
    extraEnvs:
      - name: ELASTICSEARCH_HOSTS
        valueFrom:
          configMapKeyRef:
            name: system-settings
            key: logging-host
      - name: ELASTICSEARCH_USERNAME
        valueFrom:
          configMapKeyRef:
            name: system-settings
            key: logging-username
      - name: ELASTICSEARCH_PASSWORD
        valueFrom:
          secretKeyRef:
            name: assemblyline-system-passwords
            key: logging-password
      - name: LOGGING_TLS_VERIFY
        valueFrom:
          configMapKeyRef:
            name: system-settings
            key: logging-tls-verify
      - name: METRICBEAT_INDEX
        valueFrom:
          configMapKeyRef:
            name: system-settings
            key: metricbeat-index-prefix
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            fieldPath: spec.nodeName
  metricbeatConfig:
    # Configuration on the daemonset
    metricbeat.yml: |
      logging:
        level: warning
        json: true
      name: ${NODE_NAME}

      metricbeat.modules:
        - module: system
          period: 10s
          metricsets:
            - cpu
            - load
            - memory
            - network
            - process
            - process_summary
            - uptime
            - socket_summary
            - socket
          processes: [".*"]
          cpu.metrics:  ["percentages"]
          core.metrics: ["percentages"]
          process.include_top_n:
            by_cpu: 5      # include top 5 processes by CPU
            by_memory: 5   # include top 5 processes by memory
        - module: system
          period: 1m
          metricsets:
            - diskio
            - fsstat
        - module: docker
          metricsets:
            - "container"
            - "cpu"
            - "diskio"
            - "event"
            - "healthcheck"
            - "info"
            - "memory"
            - "network"
          hosts: ["unix:///var/run/docker.sock"]
          period: 10s
          enabled: true
          processors:
            - add_docker_metadata: ~
        - module: kubernetes
          metricsets:
            - node
            - system
            - pod
            - container
            - volume
          period: 10s
          host: ${NODE_NAME}
          hosts: ["localhost:10255"]

      processors:
        - add_cloud_metadata: ~

      output.elasticsearch:
        hosts: ['${ELASTICSEARCH_HOSTS:elasticsearch}']
        username: ${ELASTICSEARCH_USERNAME}
        password: ${ELASTICSEARCH_PASSWORD}
        index: "${METRICBEAT_INDEX}-%{[agent.version]}-%{+yyyy.MM.dd}"
        ssl:
          verification_mode: ${LOGGING_TLS_VERIFY:full}

      setup.template.name: "${METRICBEAT_INDEX}"
      setup.template.pattern: "${METRICBEAT_INDEX}-*"

      setup.template.settings:
        index.number_of_shards: 1
        index.number_of_replicas: 0
      setup.ilm:
        enabled: true
        rollover_alias: ${METRICBEAT_INDEX}
        policy_file: /usr/share/metricbeat/metricbeat_policy.json

    # Configuration on the deployment
    kube-state-metrics-metricbeat.yml: |
      logging:
        level: warning
        json: true
      name: ${NODE_NAME}

      metricbeat.modules:
        - module: redis
          metricsets:
            - "info"
            - "keyspace"
          period: 10s
          hosts: ["redis-volatile:6379"]
        - module: redis
          metricsets:
            - "info"
            - "keyspace"
          period: 10s
          hosts: ["redis-persistent:6379"]

      processors:
        - add_cloud_metadata: ~

      output.elasticsearch:
        hosts: ['${ELASTICSEARCH_HOSTS:elasticsearch}']
        username: ${ELASTICSEARCH_USERNAME}
        password: ${ELASTICSEARCH_PASSWORD}
        index: "${METRICBEAT_INDEX}-%{[agent.version]}-%{+yyyy.MM.dd}"
        ssl:
          verification_mode: ${LOGGING_TLS_VERIFY:full}

      setup.template.name: "${METRICBEAT_INDEX}"
      setup.template.pattern: "${METRICBEAT_INDEX}-*"

      setup.template.settings:
        index.number_of_shards: 1
        index.number_of_replicas: 0
      setup.ilm:
        enabled: true
        rollover_alias: ${METRICBEAT_INDEX}
        policy_file: /usr/share/metricbeat/metricbeat_policy.json

    metricbeat_policy.json: |-
       {
         "policy": {
           "phases": {
             "hot": {
               "min_age": "0ms",
               "actions": {
                 "rollover": {
                   "max_age": "1d",
                   "max_size": "5gb"
                 },
                 "set_priority": {
                   "priority": 100
                 }
               }
             },
             "warm": {
               "actions": {
                 "readonly": {},
                 "set_priority": {
                   "priority": 50
                 }
               }
             },
             "delete": {
               "min_age": "4d",
               "actions": {
                 "delete": {}
               }
             }
           }
         }
       }


kibana:
  fullnameOverride: kibana
  elasticsearchHosts: http://log-storage-master:9200
  healthCheckPath: /kibana/app/kibana
  labels:
    section: core
  service:
    labels:
      section: core
  extraEnvs:
    - name: SERVER_NAME
      value: localhost
    - name: ELASTICSEARCH_USERNAME
      value: elastic
    - name: ELASTICSEARCH_PASSWORD
      valueFrom:
        secretKeyRef:
          name: assemblyline-system-passwords
          key: logging-password
    - name: SERVER_BASEPATH
      value: /kibana
    - name: SERVER_REWRITEBASEPATH
      value: "true"
    - name: LOGGING_QUIET
      value: "true"
  priorityClassName: al-core-priority


# Configuration for the internal logging elasticsearch instance, only used
# if the internal logging flag is set
log-storage:
  clusterName: "log-storage"
  replicas: 1
  extraEnvs:
  - name: ELASTIC_USERNAME
    value: elastic
  - name: ELASTIC_PASSWORD
    valueFrom:
      secretKeyRef:
        name: assemblyline-system-passwords
        key: logging-password
  labels:
    section: core
    component: log-storage
  esJavaOpts: '-Xms4g -Xmx4g'
  protocol: http
  esConfig:
    elasticsearch.yml: |
      logger.level: WARN
      xpack.security.enabled: true
      xpack.security.transport.ssl.enabled: true
      xpack.security.transport.ssl.verification_mode: certificate
      xpack.security.transport.ssl.keystore.path: /usr/share/elasticsearch/config/certs/logging-certificates.p12
      xpack.security.transport.ssl.truststore.path: /usr/share/elasticsearch/config/certs/logging-certificates.p12
      xpack.security.http.ssl.enabled: false
      xpack.security.http.ssl.truststore.path: /usr/share/elasticsearch/config/certs/logging-certificates.p12
      xpack.security.http.ssl.keystore.path: /usr/share/elasticsearch/config/certs/logging-certificates.p12
  resources:
    requests:
      cpu: 1
      memory: 5Gi
    limits:
      cpu: 6
      memory: 6Gi
  volumeClaimTemplate:
    accessModes: [ "ReadWriteOnce" ]
    storageClassName: default
    resources:
      requests:
        storage: 500Gi
  priorityClassName: 'al-infra'
  extraInitContainers: |
    - name: create-certs
      image: docker.elastic.co/elasticsearch/elasticsearch:7.8.0
      command: ['bash', '-c', "if [ ! -f /data/logging-certificates.p12 ]; then mkdir /tmp/certs/ && elasticsearch-certutil cert --name security-master --dns security-master --ca /data/elastic-stack-ca.p12 --pass '' --ca-pass '' --out /tmp/certs/logging-certificates.p12 && mv -n /tmp/certs/* /data/; fi"]
      volumeMounts:
        - name: elastic-certificates
          mountPath: /data/
  extraVolumes: |
    - name: elastic-certificates
      persistentVolumeClaim:
        claimName: datastore-certificates
  extraVolumeMounts: |
    - name: elastic-certificates
      mountPath: /usr/share/elasticsearch/config/certs

filestore:
  podLabels:
    section: core
    component: filestore
  existingSecret: internal-filestore-keys
